{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serialization - saving, loading and checkpointing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But even with all this knowledge, we’re not ready to build a real machine learning system.\n",
    "That’s because we haven’t yet covered how to save and load models\n",
    "In reality, we often train a model on one device and then want to run it to make predictions on many devices simultaneously\n",
    "In order for our models to persist beyond the execution of a single Python script,\n",
    "we need mechanisms to save and `load NDArrays, gluon Parameters, and models themselves.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import mxnet as mx\n",
    "from mxnet import nd, autograd\n",
    "from mxnet import gluon\n",
    "ctx = mx.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and loading NDArrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save and load a list of NDArrays for future use\n",
    "### We prefer to use `ndarray.save` and `ndarray.load`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = nd.ones((100, 100))\n",
    "Y = nd.zeros((100, 100))\n",
    "import os\n",
    "os.makedirs('checkpoints',exist_ok=True)\n",
    "filename=\"checkpoints/test1.params\"\n",
    "nd.save(filename,[X,Y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It’s just as easy to load a saved NDArray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "<NDArray 100x100 @cpu(0)>\n",
      "\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "<NDArray 100x100 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "A, B = nd.load(filename)\n",
    "print(A)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/qy/gluon-tutorials-zh/chapter_supervised-learning/Gluon_save_modle.ipynb\n"
     ]
    }
   ],
   "source": [
    "print(os.path.abspath('Gluon_save_modle.ipynb')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also save a dictionary where the keys are strings and the values are NDArrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict = {\"X\": X, \"Y\": Y}\n",
    "filename = \"checkpoints/test2.params\"\n",
    "nd.save(filename, mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'X': \n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " ...\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 1. 1. 1.]]\n",
      "<NDArray 100x100 @cpu(0)>, 'Y': \n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "<NDArray 100x100 @cpu(0)>}\n"
     ]
    }
   ],
   "source": [
    "C = nd.load(filename)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading the parameters of` gluon` models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gluon wraps the NDArrays corresponding to model parameters in Parameter objects.\n",
    "### We’ll often want to store and load an entire model’s parameters without having to individually extract or load the NDarrays from the Parameters via ParameterDicts in each block.\n",
    "### gluon blocks make our lives very easy by providing a `.save_params()` and `.load_params()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hidden = 256\n",
    "num_outputs = 1\n",
    "net = gluon.nn.Sequential()\n",
    "with net.name_scope():\n",
    "    net.add(gluon.nn.Dense(num_hidden, activation=\"relu\"))\n",
    "    net.add(gluon.nn.Dense(num_hidden, activation=\"relu\"))\n",
    "    net.add(gluon.nn.Dense(num_outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let’s initialize the parameters by attaching an initializer and actually passing in a datapoint to induce shape inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qy/software/anaconda3/envs/gluon/lib/python3.6/site-packages/mxnet/gluon/parameter.py:685: UserWarning: Parameter 'sequential0_dense0_weight' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n",
      "/home/qy/software/anaconda3/envs/gluon/lib/python3.6/site-packages/mxnet/gluon/parameter.py:685: UserWarning: Parameter 'sequential0_dense0_bias' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n",
      "/home/qy/software/anaconda3/envs/gluon/lib/python3.6/site-packages/mxnet/gluon/parameter.py:685: UserWarning: Parameter 'sequential0_dense1_weight' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n",
      "/home/qy/software/anaconda3/envs/gluon/lib/python3.6/site-packages/mxnet/gluon/parameter.py:685: UserWarning: Parameter 'sequential0_dense1_bias' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n",
      "/home/qy/software/anaconda3/envs/gluon/lib/python3.6/site-packages/mxnet/gluon/parameter.py:685: UserWarning: Parameter 'sequential0_dense2_weight' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n",
      "/home/qy/software/anaconda3/envs/gluon/lib/python3.6/site-packages/mxnet/gluon/parameter.py:685: UserWarning: Parameter 'sequential0_dense2_bias' is already initialized, ignoring. Set force_reinit=True to re-initialize.\n",
      "  v.initialize(None, ctx, init, force_reinit=force_reinit)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[[-2362.1072]]\n",
       "<NDArray 1x1 @cpu(0)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.collect_params().initialize(mx.init.Normal(sigma=1.), ctx=ctx)\n",
    "net(nd.ones((1, 100), ctx=ctx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let’s save the parameters, instantiate a new network, load them in and make sure that we get the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[-2362.1072]]\n",
       "<NDArray 1x1 @cpu(0)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"checkpoints/testnet.params\"\n",
    "net.save_params(filename)\n",
    "net2 = gluon.nn.Sequential()\n",
    "with net2.name_scope():\n",
    "    net2.add(gluon.nn.Dense(num_hidden, activation=\"relu\"))\n",
    "    net2.add(gluon.nn.Dense(num_hidden, activation=\"relu\"))\n",
    "    net2.add(gluon.nn.Dense(num_outputs))\n",
    "net2.load_params(filename, ctx=ctx)\n",
    "net2(nd.ones((1, 100), ctx=ctx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The practice of saving models is sometimes called checkpointing\n",
    "## it’s especially important for a number of reasons. \n",
    "### 1. We can preserve and syndicate models that are trained once.\n",
    "### 2. Some models perform best (as determined on validation data) at some epoch in the middle of training. If we checkpoint the model after each epoch, we can later select the best epoch.\n",
    "### 3. We might want to ask questions about our trained model that we didn’t think of when we first wrote the scripts for our experiments. Having the parameters lying around allows us to examine our past work without having to train from scratch. \n",
    "### 4. Sometimes people might want to run our models who don’t know how to execute training themselves or can’t access a suitable dataset for training. Checkpointing gives us a way to share our work with others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
